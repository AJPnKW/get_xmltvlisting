#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
channels_inventory.py

Version: 0.7.0

Inputs (strict)
- Uses ONLY channels-only files in repo/IPTV matching:
    *_channels_<LINEUPID>.xml
  (safe filenames; no brackets)

Outputs
1) Timestamped reports:
   - out/reports/<timestamp>/channels_inventory.csv
   - out/reports/<timestamp>/channels_inventory.txt
   - out/reports/<timestamp>/channels.json
   - out/reports/<timestamp>/channel_name_matrix.csv
2) Publish (stable, current collection):
   - IPTV/channels.json
   - IPTV/channel_name_matrix.csv

channel_name_matrix.csv columns
lineup_id,country,channel_type,channel_id,dn_1,dn_2,dn_3,call_sign,channel_number,feed,network_base,city,region,brand_scope,resolution,final_display_name
"""

from __future__ import annotations

import csv
import datetime as dt
import json
import re
from pathlib import Path
import xml.etree.ElementTree as ET

__version__ = "0.7.0"

RE_FILE = re.compile(r"^(?P<label>.+)_channels_(?P<id>\d+)\.xml$", re.IGNORECASE)
RE_CHNUM = re.compile(r"^\d{1,4}(\.\d{1,3})?$")
RE_FEED = re.compile(r"(East|West|Pacific|Mountain|\+1|Timeshift|Time\s*Shift)", re.IGNORECASE)
RE_CALLSIGN = re.compile(r"^[A-Z0-9]{2,8}([\-\.][A-Z0-9]{1,8})?$")
RE_LOCAL = re.compile(r"^(?P<net>.+?)(\s+\((?P<callsign>[^)]+)\))?\s+(?P<city>[^,]+),\s*(?P<region>[A-Z]{2})\s*$", re.IGNORECASE)


def now_stamp() -> str:
    return dt.datetime.now().strftime("%Y%m%d-%H%M%S")


def repo_root_from_script() -> Path:
    return Path(__file__).resolve().parents[1]


def country_from_label(label: str) -> str:
    u = (label or "").upper()
    if u.endswith("_CA"):
        return "CA"
    if u.endswith("_US"):
        return "US"
    return ""


def parse_channels(xml_path: Path) -> dict[str, dict]:
    out: dict[str, dict] = {}
    root = ET.parse(xml_path).getroot()
    for ch in root.findall("channel"):
        cid = (ch.attrib.get("id") or "").strip()
        if not cid:
            continue

        dns = []
        for dn_el in ch.findall("display-name"):
            t = (dn_el.text or "").strip()
            if t and t not in dns:
                dns.append(t)

        url = ""
        url_el = ch.find("url")
        if url_el is not None and (url_el.text or "").strip():
            url = (url_el.text or "").strip()

        icon_src = ""
        icon_el = ch.find("icon")
        if icon_el is not None:
            icon_src = (icon_el.attrib.get("src") or "").strip()

        out[cid] = {"display_names": dns, "url": url, "icon_src": icon_src}
    return out


def pick_dn(dns: list[str], idx: int) -> str:
    return dns[idx] if len(dns) > idx else ""


def detect_channel_number(dns: list[str]) -> str:
    for s in dns:
        if RE_CHNUM.match(s):
            return s
    return ""


def detect_feed(dns: list[str]) -> str:
    for s in dns:
        m = RE_FEED.search(s)
        if m:
            v = m.group(1)
            if v.strip() == "+1":
                return "+1"
            return v.replace("Time Shift", "Timeshift").title()
    return ""


def detect_call_sign(dns: list[str]) -> str:
    cands = []
    for s in dns:
        if RE_CHNUM.match(s):
            continue
        t = (s or "").strip()
        if t and RE_CALLSIGN.match(t) and t.upper() == t:
            cands.append(t)
    if not cands:
        return ""
    cands.sort(key=len)
    return cands[0]


def classify_channel(dn1: str) -> tuple[str, str, str, str]:
    dn1 = (dn1 or "").strip()
    if not dn1:
        return "specialty", "", "", ""
    m = RE_LOCAL.match(dn1)
    if m:
        net = (m.group("net") or "").strip()
        city = (m.group("city") or "").strip()
        region = (m.group("region") or "").strip().upper()
        return "local", net, city, region
    net = dn1.split(" (", 1)[0].strip()
    return "specialty", net, "", ""


def write_txt(path: Path, headers: list[str], rows: list[list[str]]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    colw = [len(h) for h in headers]
    for r in rows:
        for i, v in enumerate(r):
            colw[i] = max(colw[i], len(v))
    def fmt_row(r):
        return " | ".join((r[i].ljust(colw[i]) for i in range(len(headers))))
    with path.open("w", encoding="utf-8", newline="
") as f:
        f.write(fmt_row(headers) + "
")
        f.write("-+-".join(("-" * w for w in colw)) + "
")
        for r in rows:
            f.write(fmt_row(r) + "
")


def write_csv(path: Path, headers: list[str], rows: list[list[str]]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", encoding="utf-8", newline="") as f:
        w = csv.writer(f)
        w.writerow(headers)
        w.writerows(rows)


def main() -> int:
    repo = repo_root_from_script()
    iptv = repo / "IPTV"

    channel_files = []
    for p in iptv.glob("*_channels_*.xml"):
        m = RE_FILE.match(p.name)
        if not m:
            continue
        channel_files.append((m.group("id"), m.group("label"), p))

    if not channel_files:
        print("Missing channels-only files in IPTV (expected *_channels_<id>.xml)")
        return 1

    channel_files.sort(key=lambda x: int(x[0]))

    per_lineup: dict[tuple[str, str], dict[str, dict]] = {}
    for lid, label, p in channel_files:
        per_lineup[(lid, label)] = parse_channels(p)

    all_ids = sorted({cid for d in per_lineup.values() for cid in d.keys()})

    channels_json = []
    for cid in all_ids:
        display_names: list[str] = []
        url = ""
        icon_src = ""
        present_in: list[str] = []

        for (_lid, label), d in per_lineup.items():
            if cid in d:
                present_in.append(label)
                for dn in d[cid]["display_names"]:
                    if dn and dn not in display_names:
                        display_names.append(dn)
                if not url and d[cid]["url"]:
                    url = d[cid]["url"]
                if not icon_src and d[cid]["icon_src"]:
                    icon_src = d[cid]["icon_src"]

        dn1 = pick_dn(display_names, 0)
        call_sign = detect_call_sign(display_names)
        chnum = detect_channel_number(display_names)
        feed = detect_feed(display_names)
        channels_json.append({
            "channel_id": cid,
            "display_names": display_names,
            "full_name": dn1,
            "call_sign": call_sign,
            "channel_number": chnum,
            "feed": feed,
            "url": url,
            "icon_src": icon_src,
            "present_in": present_in,
        })

    stamp = now_stamp()
    out_dir = repo / "out" / "reports" / stamp
    out_dir.mkdir(parents=True, exist_ok=True)

    inv_headers = ["channel_id", "display_name"] + [label for (_lid, label) in per_lineup.keys()]
    inv_rows = []
    for cid in all_ids:
        dn = ""
        for (_lid, _label), d in per_lineup.items():
            if cid in d and d[cid]["display_names"]:
                dn = d[cid]["display_names"][0]
                break
        flags = []
        for (_lid, label) in per_lineup.keys():
            flags.append("Y" if cid in per_lineup[(_lid, label)] else "")
        inv_rows.append([cid, dn, *flags])

    write_csv(out_dir / "channels_inventory.csv", inv_headers, inv_rows)
    write_txt(out_dir / "channels_inventory.txt", inv_headers, inv_rows)

    (out_dir / "channels.json").write_text(json.dumps(channels_json, ensure_ascii=False, indent=2), encoding="utf-8")
    (iptv / "channels.json").write_text(json.dumps(channels_json, ensure_ascii=False, indent=2), encoding="utf-8")

    matrix_headers = [
        "lineup_id",
        "country",
        "channel_type",
        "channel_id",
        "dn_1",
        "dn_2",
        "dn_3",
        "call_sign",
        "channel_number",
        "feed",
        "network_base",
        "city",
        "region",
        "brand_scope",
        "resolution",
        "final_display_name",
    ]

    matrix_rows = []
    for (lid, label), d in per_lineup.items():
        country = country_from_label(label)
        for cid, meta in d.items():
            dns = meta.get("display_names", []) or []
            dn1 = pick_dn(dns, 0)
            dn2 = pick_dn(dns, 1)
            dn3 = pick_dn(dns, 2)
            chnum = detect_channel_number(dns)
            call_sign = detect_call_sign(dns)
            feed = detect_feed(dns)
            channel_type, network_base, city, region = classify_channel(dn1)

            matrix_rows.append([
                lid,
                country,
                channel_type,
                cid,
                dn1,
                dn2,
                dn3,
                call_sign,
                chnum,
                feed,
                network_base,
                city,
                region,
                "",
                "",
                "",
            ])

    def sort_key(r):
        country = r[1]
        lid = int(r[0]) if r[0].isdigit() else 999999999
        chnum = r[8]
        try:
            cnum = float(chnum) if chnum else 999999.0
        except Exception:
            cnum = 999999.0
        name = r[4]
        return (country, lid, cnum, name.casefold() if isinstance(name, str) else name)

    matrix_rows.sort(key=sort_key)

    write_csv(out_dir / "channel_name_matrix.csv", matrix_headers, matrix_rows)
    write_csv(iptv / "channel_name_matrix.csv", matrix_headers, matrix_rows)

    print("Wrote:", out_dir / "channels_inventory.csv")
    print("Wrote:", out_dir / "channels_inventory.txt")
    print("Wrote:", out_dir / "channels.json")
    print("Wrote:", iptv / "channels.json")
    print("Wrote:", out_dir / "channel_name_matrix.csv")
    print("Wrote:", iptv / "channel_name_matrix.csv")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
